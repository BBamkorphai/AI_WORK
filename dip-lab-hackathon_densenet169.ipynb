{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":84870,"databundleVersionId":9546329,"sourceType":"competition"}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install torchsummary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-16T13:48:03.740869Z","iopub.execute_input":"2024-09-16T13:48:03.741624Z","iopub.status.idle":"2024-09-16T13:48:16.778285Z","shell.execute_reply.started":"2024-09-16T13:48:03.741584Z","shell.execute_reply":"2024-09-16T13:48:16.776977Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchsummary import summary\nimport time\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom datetime import datetime","metadata":{"execution":{"iopub.status.busy":"2024-09-16T13:48:16.781159Z","iopub.execute_input":"2024-09-16T13:48:16.782059Z","iopub.status.idle":"2024-09-16T13:48:16.788068Z","shell.execute_reply.started":"2024-09-16T13:48:16.782013Z","shell.execute_reply":"2024-09-16T13:48:16.787043Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport os\nfrom sklearn.model_selection import train_test_split\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader\nimport matplotlib as plt\nimport numpy as np\nimport pandas as pd\n\nimage_paths = ['/kaggle/input/dip-lab-hackathon-2024-image-classification/data/train', '/kaggle/input/dip-lab-hackathon-2024-image-classification/data/test']\n\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224),    \n    transforms.RandomHorizontalFlip(),    \n    transforms.RandomRotation(15),        \n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), \n    transforms.ToTensor(),                \n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),   \n])\n\nval_transform = transforms.Compose([\n    transforms.Resize(256),              \n    transforms.CenterCrop(224),           \n    transforms.ToTensor(),               \n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  \n])\n\nDs_target = datasets.ImageFolder(root='/kaggle/input/dip-lab-hackathon-2024-image-classification/data/train', transform=train_transform)\n\ntrain_size = int(0.9 * len(Ds_target))\nval_size = len(Ds_target) - train_size\ntraining_set, validation_set = torch.utils.data.random_split(Ds_target, [train_size, val_size])\n\nvalidation_set.dataset.transform = val_transform\n\ntraining_loader = DataLoader(training_set, batch_size=64, shuffle=True)\nvalidation_loader = DataLoader(validation_set, batch_size=64, shuffle=False)\n\nprint(f\"Training set size: {len(training_set)}\")\nprint(f\"Validation set size: {len(validation_set)}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T13:48:16.789586Z","iopub.execute_input":"2024-09-16T13:48:16.789931Z","iopub.status.idle":"2024-09-16T13:48:16.865962Z","shell.execute_reply.started":"2024-09-16T13:48:16.789897Z","shell.execute_reply":"2024-09-16T13:48:16.864861Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Training set size: 4502\nValidation set size: 501\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport os\nimport time\nfrom torchvision import models\n\n# Set device to GPU if available, otherwise CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load the pretrained DenseNet201 model\ndensenet169 = models.densenet169(pretrained=True)\n\n# Freeze all layers except the classifier\nfor param in densenet169.parameters():\n    param.requires_grad = True\n\n# Update the classifier to match the number of output classes (e.g., 10)\nnum_classes = 10\ndensenet169.classifier = nn.Linear(densenet169.classifier.in_features, num_classes)\n\n# Move the entire model to the correct device (GPU/CPU)\ndensenet169 = densenet169.to(device)\n\n# Define loss function and optimizer\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(densenet169.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\nepoch_number = 0\nEPOCHS = 20\npath_save_cp = './cp/'\nbest_vloss = 1_000_000.\ntraining_logs = {\"train_loss\": [], \"train_acc\": [], \"validate_loss\": [], \"validate_acc\": []}\n\n# Start the training loop\nt_0_accelerated = time.time()\nfor epoch in range(EPOCHS):\n    train_loss, train_correct = 0, 0\n\n    # Set model to training mode\n    densenet169.train(True)\n\n    # Iterate through training data\n    for i, data in enumerate(training_loader):\n        inputs, labels = data[0].to(device), data[1].to(device)  # Move inputs and labels to the device\n\n        # Zero your gradients for every batch!\n        optimizer.zero_grad()\n\n        # Forward pass: Make predictions\n        outputs = densenet169(inputs)\n\n        # Compute loss and backpropagate\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n\n        # Update weights\n        optimizer.step()\n\n        train_loss += loss.item()\n        train_correct += (outputs.argmax(1) == labels).float().sum().item()\n\n    # Step the scheduler\n    scheduler.step()\n\n    # Log training loss and accuracy\n    training_logs[\"train_loss\"].append(train_loss / len(training_loader))\n    training_logs[\"train_acc\"].append(train_correct / len(training_loader.dataset))\n\n    # Validation\n    running_vloss = 0.0\n    densenet169.eval()  # Set model to evaluation mode\n    valid_loss, valid_correct = 0, 0\n    with torch.no_grad():\n        for i, vdata in enumerate(validation_loader):\n            vinputs, vlabels = vdata[0].to(device), vdata[1].to(device)  # Move validation data to device\n            voutputs = densenet169(vinputs)\n            vloss = loss_fn(voutputs, vlabels)\n            valid_loss += vloss.item()\n            valid_correct += (voutputs.argmax(1) == vlabels).float().sum().item()\n\n    # Log validation loss and accuracy\n    training_logs[\"validate_loss\"].append(valid_loss / len(validation_loader))\n    training_logs[\"validate_acc\"].append(valid_correct / len(validation_loader.dataset))\n\n    # Print progress\n    if epoch % 1 == 0:\n        print(f\"Epoch {epoch+1}\".ljust(10),\n              f\"Train Loss: {training_logs['train_loss'][-1]:.5f}\",\n              f\"Train Acc: {training_logs['train_acc'][-1]:.5f}\",\n              f\"Validation Loss: {training_logs['validate_loss'][-1]:.5f}\",\n              f\"Validation Acc: {training_logs['validate_acc'][-1]:.5f}\")\n        print(\"-\" * 80)\n\n    # Save best model\n    if valid_loss < best_vloss:\n        best_vloss = valid_loss\n        if not os.path.exists(path_save_cp):\n            os.mkdir(path_save_cp)\n        torch.save(densenet169.state_dict(), path_save_cp + 'best_pretrainedmodel.pth')\n\n    epoch_number += 1\n\nt_end_accelerated = time.time() - t_0_accelerated\nprint(f\"Time consumption for accelerated CUDA training (device:{device}): {t_end_accelerated} sec\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T13:48:16.868875Z","iopub.execute_input":"2024-09-16T13:48:16.869483Z","iopub.status.idle":"2024-09-16T14:18:39.362316Z","shell.execute_reply.started":"2024-09-16T13:48:16.869446Z","shell.execute_reply":"2024-09-16T14:18:39.361082Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 1    Train Loss: 2.10680 Train Acc: 0.25322 Validation Loss: 1.66864 Validation Acc: 0.50699\n--------------------------------------------------------------------------------\nEpoch 2    Train Loss: 1.22800 Train Acc: 0.65260 Validation Loss: 0.86183 Validation Acc: 0.75449\n--------------------------------------------------------------------------------\nEpoch 3    Train Loss: 0.66435 Train Acc: 0.80675 Validation Loss: 0.51884 Validation Acc: 0.83832\n--------------------------------------------------------------------------------\nEpoch 4    Train Loss: 0.40147 Train Acc: 0.88272 Validation Loss: 0.43084 Validation Acc: 0.86427\n--------------------------------------------------------------------------------\nEpoch 5    Train Loss: 0.24244 Train Acc: 0.93025 Validation Loss: 0.38352 Validation Acc: 0.89022\n--------------------------------------------------------------------------------\nEpoch 6    Train Loss: 0.14250 Train Acc: 0.96690 Validation Loss: 0.36092 Validation Acc: 0.89820\n--------------------------------------------------------------------------------\nEpoch 7    Train Loss: 0.08051 Train Acc: 0.98512 Validation Loss: 0.37803 Validation Acc: 0.89421\n--------------------------------------------------------------------------------\nEpoch 8    Train Loss: 0.05262 Train Acc: 0.99178 Validation Loss: 0.36316 Validation Acc: 0.90020\n--------------------------------------------------------------------------------\nEpoch 9    Train Loss: 0.04266 Train Acc: 0.99600 Validation Loss: 0.36762 Validation Acc: 0.90220\n--------------------------------------------------------------------------------\nEpoch 10   Train Loss: 0.04093 Train Acc: 0.99556 Validation Loss: 0.36514 Validation Acc: 0.90220\n--------------------------------------------------------------------------------\nEpoch 11   Train Loss: 0.03581 Train Acc: 0.99689 Validation Loss: 0.37348 Validation Acc: 0.90220\n--------------------------------------------------------------------------------\nEpoch 12   Train Loss: 0.03380 Train Acc: 0.99645 Validation Loss: 0.36872 Validation Acc: 0.90419\n--------------------------------------------------------------------------------\nEpoch 13   Train Loss: 0.03390 Train Acc: 0.99733 Validation Loss: 0.36839 Validation Acc: 0.90619\n--------------------------------------------------------------------------------\nEpoch 14   Train Loss: 0.03462 Train Acc: 0.99600 Validation Loss: 0.36410 Validation Acc: 0.90020\n--------------------------------------------------------------------------------\nEpoch 15   Train Loss: 0.02997 Train Acc: 0.99733 Validation Loss: 0.36364 Validation Acc: 0.89621\n--------------------------------------------------------------------------------\nEpoch 16   Train Loss: 0.02979 Train Acc: 0.99778 Validation Loss: 0.36644 Validation Acc: 0.89820\n--------------------------------------------------------------------------------\nEpoch 17   Train Loss: 0.03072 Train Acc: 0.99733 Validation Loss: 0.36755 Validation Acc: 0.90619\n--------------------------------------------------------------------------------\nEpoch 18   Train Loss: 0.02921 Train Acc: 0.99756 Validation Loss: 0.36331 Validation Acc: 0.90419\n--------------------------------------------------------------------------------\nEpoch 19   Train Loss: 0.03427 Train Acc: 0.99711 Validation Loss: 0.35991 Validation Acc: 0.90220\n--------------------------------------------------------------------------------\nEpoch 20   Train Loss: 0.02940 Train Acc: 0.99800 Validation Loss: 0.36461 Validation Acc: 0.89621\n--------------------------------------------------------------------------------\nEpoch 21   Train Loss: 0.02891 Train Acc: 0.99822 Validation Loss: 0.37396 Validation Acc: 0.89820\n--------------------------------------------------------------------------------\nEpoch 22   Train Loss: 0.03213 Train Acc: 0.99778 Validation Loss: 0.36541 Validation Acc: 0.90419\n--------------------------------------------------------------------------------\nEpoch 23   Train Loss: 0.02834 Train Acc: 0.99822 Validation Loss: 0.37618 Validation Acc: 0.89421\n--------------------------------------------------------------------------------\nEpoch 24   Train Loss: 0.03067 Train Acc: 0.99845 Validation Loss: 0.36904 Validation Acc: 0.90220\n--------------------------------------------------------------------------------\nEpoch 25   Train Loss: 0.02920 Train Acc: 0.99800 Validation Loss: 0.37012 Validation Acc: 0.89222\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 61\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     train_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (outputs\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Step the scheduler\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nloss_fn = torch.nn.CrossEntropyLoss()\n\nPATH = '/kaggle/working/cp/best_pretrainedmodel.pth'\n\n\nmodel = models.densenet169(pretrained=False)\nmodel.classifier = torch.nn.Linear(model.classifier.in_features, 10)\n\nmodel.load_state_dict(torch.load(PATH, map_location=device), strict=False)\n\nmodel.to(device)\n\nmodel.eval()\n\nacc_test = 0\ntest_loss = 0\n\n\nwith torch.no_grad():\n    for tinputs, tlabels in validation_loader:\n        tinputs, tlabels = tinputs.to(device), tlabels.to(device)\n\n\n        toutputs = model(tinputs)\n\n\n        loss = loss_fn(toutputs, tlabels)\n        test_loss += loss.item()\n\n \n        _, preds_t = torch.max(toutputs, 1)\n        acc_test += (preds_t == tlabels).float().sum().item()\n\naccuracy_t = round(acc_test / len(validation_loader.dataset) * 100, 2)\navg_tloss = test_loss / len(validation_loader)\n\nprint(f'[Test loss: {avg_tloss}] [Accuracy test: {accuracy_t}%]')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T14:18:56.584897Z","iopub.execute_input":"2024-09-16T14:18:56.585596Z","iopub.status.idle":"2024-09-16T14:19:00.738752Z","shell.execute_reply.started":"2024-09-16T14:18:56.585553Z","shell.execute_reply":"2024-09-16T14:19:00.737810Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1110901835.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(PATH, map_location=device), strict=False)\n","output_type":"stream"},{"name":"stdout","text":"[Test loss: 0.35990913584828377] [Accuracy test: 90.22%]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\nmodel.eval()\ndf = pd.read_csv(\"/kaggle/input/dip-lab-hackathon-2024-image-classification/sample-submission.csv\")\nimage_dir = '/kaggle/input/dip-lab-hackathon-2024-image-classification/data/test/data'\npredictions = []\n\nfor idx, row in df.iterrows():\n    image_path = os.path.join(image_dir, row['ID'])\n    image = Image.open(image_path)\n    \n    image = val_transform(image).unsqueeze(0)\n    \n    if torch.cuda.is_available():\n        image = image.cuda()\n        loaded_model = model.cuda()\n    \n    with torch.no_grad():\n        output = model(image)\n        _, predicted = torch.max(output, 1)\n    \n    predictions.append(predicted.item())\n\ndf['predicted_class'] = predictions\n\ndf.to_csv('/kaggle/working/submission.csv', index=False)\n\nprint(\"CSV file updated with predictions.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T14:19:05.596604Z","iopub.execute_input":"2024-09-16T14:19:05.596957Z","iopub.status.idle":"2024-09-16T14:20:18.258605Z","shell.execute_reply.started":"2024-09-16T14:19:05.596924Z","shell.execute_reply":"2024-09-16T14:20:18.257585Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"CSV file updated with predictions.\n","output_type":"stream"}]}]}