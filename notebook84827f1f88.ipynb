{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install torchsummary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-17T11:39:52.294443Z","iopub.execute_input":"2024-08-17T11:39:52.294723Z","iopub.status.idle":"2024-08-17T11:40:06.218071Z","shell.execute_reply.started":"2024-08-17T11:39:52.294697Z","shell.execute_reply":"2024-08-17T11:40:06.216931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchsummary import summary\n\n# Set the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Transform to resize images to 224x224 and normalize them\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n# Download and load CIFAR-10 dataset\ntraining_set = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\nvalidation_set = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n\n\ntraining_loader = torch.utils.data.DataLoader(training_set, batch_size=64, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(validation_set, batch_size=64, shuffle=False)\n\n\n# CIFAR-10 class labels\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n\nclass DeepModelT4(nn.Module):\n    def __init__(self):\n        super(DeepModelT4, self).__init__()\n        self.pool_1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv_1_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.conv_1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.conv_2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.conv_2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.conv_3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n        self.conv_3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n        self.conv_3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n        self.conv_3_4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n        self.conv_4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n        self.conv_4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n        self.conv_4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n        self.conv_4_4 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n        self.conv_5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n        self.conv_5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n        self.conv_5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n        self.conv_5_4 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(7*7*512, 4096)\n        self.fc2 = nn.Linear(4096, 4096)\n        self.fc3 = nn.Linear(4096, 10)\n        self.dropout = nn.Dropout(0.5) \n    \n    def forward(self, x):\n        # Block 1\n        x = self.conv_1_1(x)\n        x = F.relu(self.conv_1_2(x))\n        x = self.pool_1(x)\n\n        # Conv Block 2\n        x = self.conv_2_1(x)\n        x = F.relu(self.conv_2_2(x))\n        x = self.pool_1(x)\n\n        # Conv Block 3\n        x = self.conv_3_1(x)\n        x = self.conv_3_2(x)\n        x = self.conv_3_3(x)\n        x = F.relu(self.conv_3_4(x))\n        x = self.pool_1(x)\n\n        # Conv Block 4\n        x = self.conv_4_1(x)\n        x = self.conv_4_2(x)\n        x = self.conv_4_3(x)\n        x = F.relu(self.conv_4_4(x))\n        x = self.pool_1(x)\n\n        # Conv Block 5\n        x = self.conv_5_1(x)\n        x = self.conv_5_2(x)\n        x = self.conv_5_3(x)\n        x = F.relu(self.conv_5_4(x))\n        x = self.pool_1(x)\n\n        # Flatten the output for the fully connected layers\n        x = x.view(x.size(0), -1)\n\n        # Fully Connected Layers\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = self.fc3(x)\n        return x\n\n\n    \n# Initialize the model and move to device\nmodel = DeepModelT4().to(device)\n\nmodel= nn.DataParallel(model)\nmodel.to(device)\n\n# Print model summary for an input size of 3x224x224\nsummary(model, (3, 224, 224))\n\n# Loss function\nloss_fn = torch.nn.CrossEntropyLoss()\n# Optimizers specified in the torch.optim package\n\n\n#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\nEPOCHS = 20\nepoch_number = 0\n\n\npath_save_cp = './cp/'\nbest_vloss = 1_000_000.\ntraining_logs = {\"train_loss\": [],  \"train_acc\": [], \"validate_loss\": [], \"validate_acc\": []}\n\nt_0_accelerated = time.time()\nfor epoch in range(EPOCHS):\n    train_loss, train_correct = 0, 0\n    # Make sure gradient tracking is on, and do a pass over the data\n    model.train(True)\n    # Here, we use enumerate(training_loader) instead of\n    # iter(training_loader) so that we can track the batch\n    # index and do some intra-epoch reporting\n    for i, data in enumerate(training_loader):\n        # Every data instance is an input + label pair\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        # Zero your gradients for every batch!\n        optimizer.zero_grad()\n\n        # Make predictions for this batch\n        outputs = model(inputs)\n\n        # Compute the loss and its gradients\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n\n        # Adjust learning weights\n        optimizer.step()\n\n        train_loss += loss.item()\n        train_correct += (outputs.argmax(1) == labels).float().sum().item()\n\n    training_logs[\"train_loss\"].append(train_loss / len(training_loader))\n    training_logs[\"train_acc\"].append(train_correct / len(training_loader.dataset))\n\n    running_vloss = 0.0\n    # Set the model to evaluation mode, disabling dropout and using population\n    # statistics for batch normalization.\n    model.eval()\n    # Disable gradient computation and reduce memory consumption.\n    valid_loss, valid_correct = 0, 0\n    with torch.no_grad():\n        for i, vdata in enumerate(validation_loader):\n            vinputs, vlabels = vdata[0].to(device), vdata[1].to(device)\n            voutputs = model(vinputs)\n            vloss = loss_fn(voutputs, vlabels)\n            valid_loss += loss_fn(voutputs, vlabels).item()\n            valid_correct += (voutputs.argmax(1) == vlabels).float().sum().item()\n        # save validation logs\n        training_logs[\"validate_loss\"].append(valid_loss / len(validation_loader))\n        training_logs[\"validate_acc\"].append(valid_correct / len(validation_loader.dataset))\n\n    if epoch % 1 == 0:\n        print(f\"Epochs {epoch+1}\".ljust(10),\n            f\"train loss {training_logs['train_loss'][-1]:.5f}\",\n            f\"train acc {training_logs['train_acc'][-1]:.5f}\",\n\n            f\"validate loss {training_logs['validate_loss'][-1]:.5f}\",\n            f\"validate acc {training_logs['validate_acc'][-1]:.5f}\",\n            )\n        print(\"-\"*80)\n\n    # Track best performance, and save the model's state\n    if valid_loss < best_vloss:\n        best_vloss = valid_loss\n        # model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n        if not os.path.exists(path_save_cp): os.mkdir(path_save_cp)\n        torch.save(model.state_dict(), path_save_cp+'best_model.pth')\n\n    epoch_number += 1\n\nt_end_accelerated = time.time()-t_0_accelerated\nprint(f\"Time consumption for accelerated CUDA training (T4): {t_end_accelerated} sec\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-17T11:40:06.220617Z","iopub.execute_input":"2024-08-17T11:40:06.221222Z"},"trusted":true},"execution_count":null,"outputs":[]}]}